{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "5a005358",
            "metadata": {},
            "source": [
                "# GPT4All Langchain Demo\n",
                "\n",
                "Example of locally running [`GPT4All`](https://github.com/nomic-ai/gpt4all), a 4GB, *llama.cpp* based large language model (LLM) under [`langchain`](https://github.com/hwchase17/langchain), in a Jupyter notebook running a Python 3.10 kernel.\n",
                "\n",
                "*Tested on a mid-2015 16GB Macbook Pro, concurrently running Docker (a single container running a sepearate Jupyter server) and Chrome with approx. 40 open tabs).*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "871e5f12",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "langchain                     0.0.142\n",
                        "torch                         2.0.0\n",
                        "torchvision                   0.15.1\n",
                        "llama-cpp-python              0.1.43\n",
                        "llama-index                   0.5.27\n",
                        "pyllama                       0.0.9\n",
                        "pyllamacpp                    2.1.2\n"
                    ]
                }
            ],
            "source": [
                "!pip install -qU chromadb langchain==0.0.142 tiktoken tqdm load_dotenv ipywidgets pinecone-client pyllama llama-index llama-cpp-python html2text pyllamacpp\n",
                "!pip list | grep langchain\n",
                "!pip list | grep torch\n",
                "!pip list | grep llama"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "bf25336f",
            "metadata": {},
            "source": [
                "## Data preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "633bef28",
            "metadata": {},
            "outputs": [],
            "source": [
                "def file_metadata(filename):\n",
                "    d = dict()\n",
                "    d[\"source\"] = filename.replace('../data/docs/', 'https://').replace('index.html', '').replace('.html', '')\n",
                "    return d"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "157af9ba",
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "from typing import Dict\n",
                "\n",
                "from llama_index.readers.file.base_parser import BaseParser\n",
                "\n",
                "class HtmlParser(BaseParser):\n",
                "    \"\"\"Html parser.\"\"\"\n",
                "\n",
                "    def _init_parser(self) -> Dict:\n",
                "        \"\"\"Init parser.\"\"\"\n",
                "        return {}\n",
                "\n",
                "    def parse_file(self, file: Path, errors: str = \"ignore\") -> str:\n",
                "        \"\"\"Parse file.\"\"\"\n",
                "        try:\n",
                "            import html2text\n",
                "        except ImportError:\n",
                "            raise ImportError(\n",
                "                \"html2text is required to read html files: `pip install html2text`\"\n",
                "            )\n",
                "        with open(file, \"r\") as fp:\n",
                "            text = fp.read()\n",
                "            text_maker = html2text.HTML2Text()\n",
                "            text_maker.ignore_links = True\n",
                "            text_maker.ignore_images = True\n",
                "            text_maker.bypass_tables = False\n",
                "            text = text_maker.handle(text)\n",
                "            # Remove extra white space\n",
                "            text = ' '.join(text.split())\n",
                "\n",
                "        return text"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "acfaa49e",
            "metadata": {},
            "outputs": [],
            "source": [
                "file_extractor: Dict[str, BaseParser] = {\n",
                "    \".htm\": HtmlParser(),\n",
                "    \".html\": HtmlParser(),\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "b8128240",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 10.4 s, sys: 250 ms, total: 10.7 s\n",
                        "Wall time: 10.9 s\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "171"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "from llama_index import SimpleDirectoryReader\n",
                "docs = SimpleDirectoryReader(input_dir='../data/docs/', recursive=True, file_extractor=file_extractor, file_metadata=file_metadata).load_langchain_documents()\n",
                "len(docs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "a23d691b",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "5db27cc843d9419b946eeb29ddad5dac",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/171 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 5.62 ms, sys: 2.38 ms, total: 8 ms\n",
                        "Wall time: 12 ms\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(3,\n",
                            " Document(page_content=\"### Add to wishlist Follow ADD TO CART Waitlist 0 Log in Sign up Language Currency Interests Locations * * * Mastercard.com About Priceless Contact us ADVANCED SEARCH All Experiences Interests Entertainment Arts and Culture Sports Culinary Travel More... Shopping Less... Locations Argentina Australia Austria Brazil Bulgaria More... Canada Chile China Colombia Croatia Czechia Fiji France Germany Greece Hong Kong India Indonesia Ireland Italy Japan Kenya Macau Malaysia Maldives Mexico Morocco Netherlands New Zealand Nigeria Puerto Rico Romania Serbia Singapore South Africa Spain Sweden Thailand Turkey United Arab Emirates United Kingdom United States Uruguay Clear Selection ADVANCED SEARCH ADVANCED SEARCH All Experiences Interests Entertainment Arts and Culture Sports Culinary Travel More... Shopping Less... Locations Argentina Australia Austria Brazil Bulgaria More... Canada Chile China Colombia Croatia Czechia Fiji France Germany Greece Hong Kong India Indonesia Ireland Italy Japan Kenya Macau Malaysia Maldives Mexico Morocco Netherlands New Zealand Nigeria Puerto Rico Romania Serbia Singapore South Africa Spain Sweden Thailand Turkey United Arab Emirates United Kingdom United States Uruguay Clear Selection ADVANCED SEARCH Filter Location * All locations * Argentina (0) * All locations * Buenos Aires (0) * Australia (0) * All locations * Brisbane (0) * Melbourne (0) * Sydney (0) * Austria (0) * Brazil (0) * All locations * Rio de Janeiro (0) * São Paulo (0) * Trancoso (0) * Bulgaria (0) * Canada (0) * All locations * Montreal (0) * Toronto (0) * Chile (0) * All locations * Santiago (0) * China (0) * All locations * Beijing (0) * Colombia (0) * All locations * Bogotá (0) * Croatia (0) * Czech Republic (0) * All locations * Prague (0) * Fiji (0) * France (0) * All locations * Paris (0) * Germany (0) * All locations * Berlin (0) * Munich (0) * Greece (0) * Hong Kong (0) * India (0) * Indonesia (0) * All locations * Bali (0) * Ireland (0) * Italy (0) * All locations * Milan (0) * Rome (0) * Sicily (0) * Japan (0) * Kenya (0) * Macau (0) * Malaysia (0) * Mexico (0) * All locations * Mexico City (0) * Morocco (0) * Netherlands (0) * New Zealand (0) * Nigeria (0) * Puerto Rico (0) * All locations * San Juan (0) * Romania (0) * Serbia (0) * Singapore (0) * South Africa (0) * Spain (0) * All locations * Barcelona (0) * Madrid (0) * Sweden (0) * All locations * Stockholm (0) * Thailand (0) * All locations * Bangkok (0) * Turkey (0) * All locations * Istanbul (0) * United Arab Emirates (0) * United Kingdom (0) * All locations * London (0) * St Andrews (0) * United States (0) * All locations * Boston (0) * Chicago (0) * Hawaii (0) * Las Vegas (0) * Los Angeles (0) * Miami (0) * New York (0) * Uruguay (0) Categories * All categories * Arts and Culture * Sports * Culinary * Travel * Shopping * Entertainment * Giving back Time range Select from preset options Weekdays Only Weekends Only Next 2 weeks Next Month Next 3 Months Next 6 Months Or Must choose a from date first. from April 2023 Select Time Select Time *Please select time *Please select a date/time that is greater than the current date/time. All experiences take place in the local timezone. Mastercard product * All Mastercard products * Mastercard Black™ * World Elite™ Mastercard® * World Mastercard® * Platinum Mastercard® * World Mastercard Black Edition® * Gold Mastercard® * Titanium Mastercard™ * World Mastercard™ (Europe) * Mastercard® Standard * World Mastercard® Rewards * Mastercard Rewards Only Content Type * All content types * Experiences * Digital experiences * Articles * Auctions * Sweepstakes * Offers * All offers * Mastercard Travel Rewards * Mastercard Travel and Lifestyle Services * Benefits Filter Results : 1772 Listings Find Cancel Location * All locations * Argentina (0) * All locations * Buenos Aires (0) * Australia (0) * All locations * Brisbane (0) * Melbourne (0) * Sydney (0) * Austria (0) * Brazil (0) * All locations * Rio de Janeiro (0) * São Paulo (0) * Trancoso (0) * Bulgaria (0) * Canada (0) * All locations * Montreal (0) * Toronto (0) * Chile (0) * All locations * Santiago (0) * China (0) * All locations * Beijing (0) * Colombia (0) * All locations * Bogotá (0) * Croatia (0) * Czech Republic (0) * All locations * Prague (0) * Fiji (0) * France (0) * All locations * Paris (0) * Germany (0) * All locations * Berlin (0) * Munich (0) * Greece (0) * Hong Kong (0) * India (0) * Indonesia (0) * All locations * Bali (0) * Ireland (0) * Italy (0) * All locations * Milan (0) * Rome (0) * Sicily (0) * Japan (0) * Kenya (0) * Macau (0) * Malaysia (0) * Mexico (0) * All locations * Mexico City (0) * Morocco (0) * Netherlands (0) * New Zealand (0) * Nigeria (0) * Puerto Rico (0) * All locations * San Juan (0) * Romania (0) * Serbia (0) * Singapore (0) * South Africa (0) * Spain (0) * All locations * Barcelona (0) * Madrid (0) * Sweden (0) * All locations * Stockholm (0) * Thailand (0) * All locations * Bangkok (0) * Turkey (0) * All locations * Istanbul (0) * United Arab Emirates (0) * United Kingdom (0) * All locations * London (0) * St Andrews (0) * United States (0) * All locations * Boston (0) * Chicago (0) * Hawaii (0) * Las Vegas (0) * Los Angeles (0) * Miami (0) * New York (0) * Uruguay (0) Categories * All categories * Arts and Culture * Sports * Culinary * Travel * Shopping * Entertainment * Giving back Mastercard product * All Mastercard products * Mastercard Black™ * World Elite™ Mastercard® * World Mastercard® * Platinum Mastercard® * World Mastercard Black Edition® * Gold Mastercard® * Titanium Mastercard™ * World Mastercard™ (Europe) * Mastercard® Standard * World Mastercard® Rewards * Mastercard Rewards Only Time range Weekdays Only Weekends Only Next 2 weeks Next Month Next 3 Months Next 6 Months Or Specify time range April 2023 April 2023 Clear Selection Content type * All content types * Experiences * Digital experiences * Articles * Auctions * Sweepstakes * Offers * All offers * Mastercard Travel Rewards * Mastercard Travel and Lifestyle Services * Benefits # 1772 Results '' Clear All All Experiences 1772 Results \\\\- FILTER , '' Clear All View more Sorry, there are no results to display. Please check back soon as we are continually adding new results. You may also enjoy these offers Follow us * (opens in new tab) * (opens in new tab) * Contact us (opens in new tab) * Terms of Use (opens in new tab) * About Priceless (opens in new tab) * Privacy Notice (opens in new tab) * Mastercard.com (opens in new tab) * Manage cookies * Sitemap (opens in new tab) Mastercard and Priceless are registered trademarks, and the circles design is a trademark of Mastercard International Incorporated. ©2023 Mastercard as01-SI5-SCOPx5Txqt7jJhvBCZPV6N-SO0-U0-V-L1-H7-mA0-uA1-auto0-exec:0.487-ajax:0-total:0.487 Verify card Login details Done Register to reveal content specific to your Mastercard, including: * Priority access to events * Complimentary digital experiences * Exclusive content * Shopping discounts, travel rewards, and more! Continue Already have an account? Log in Email Password Password must be at least 8 characters with three of: uppercase, lowercase, numbers or special characters. Space, dictionary words and repetitive or sequential characters are not allowed. Location / Region Location / Region AfghanistanAlgeriaAngolaArgentinaArubaAustraliaAustriaAzerbaijanBahamasBahrainBelgiumBeninBoliviaBosnia and HerzegovinaBotswanaBrazilBulgariaBurkina FasoBurundiCameroonCanadaCape VerdeCayman IslandsCentral African RepublicChadChileChinaColombiaComorosCongoCosta RicaCote D'Ivoire (Ivory Coast)CroatiaCyprusCzech RepublicDemocratic Republic of the CongoDenmarkDjiboutiDominican RepublicEcuadorEgyptEl SalvadorEquatorial GuineaEstoniaEthiopiaFijiFinlandFranceGabonGambiaGermanyGhanaGreeceGuatemalaGuineaGuinea- BissauHondurasHong KongHungaryIndiaIndonesiaIraqIrelandIsraelItalyJamaicaJapanJordanKenyaKuwaitLatviaLebanonLesothoLiberiaLibyaLithuaniaLuxembourgMacaoMadagascarMalawiMalaysiaMaldivesMaliMaltaMauritaniaMauritiusMexicoMoldovaMontenegroMoroccoMozambiqueNamibiaNetherlandsNew ZealandNicaraguaNigerNigeriaNorth MacedoniaNorwayOmanPakistanPalestinePanamaParaguayPeruPhilippinesPolandPortugalPuerto RicoQatarRomaniaRwandaSaudi ArabiaSenegalSerbiaSeychellesSierra LeoneSingaporeSlovakiaSloveniaSomaliaSouth AfricaSouth KoreaSpainSri LankaSwazilandSwedenSwitzerlandTaiwanTanzaniaThailandTogoTunisiaTurkeyTurks and Caicos IslandsUgandaUnited Arab EmiratesUnited KingdomUnited StatesUruguayVietnamYemenZambiaZimbabwe I agree that Mastercard International Inc. and its affiliates may use my contact details and interactions with priceless.com to send me personalized marketing communications about all Priceless programs. Information on Mastercard’s privacy practices is available in the priceless.com Privacy Notice. By clicking Sign Up, I confirm that I have read and agree to the Terms of Use for priceless.com. Submit Thank you! Please check your email to complete registration. You're all set! Start Something Priceless Explore priceless.com Already have an account? Log in here # Connect to Priceless * * Log In * Create Account Forgot Password? * * Sign up The Terms of Use and Privacy Notice for Priceless have been updated since you last logged in. * * *By clicking “Continue”, I acknowledge that I have read and understand the Terms of Use for Priceless. I also understand that my personal data will be processed by Mastercard International Inc. and its affiliates in the context of Priceless as described in the Privacy Notice. * * * Continue Complete your registration to unlock unique experiences tailored to your specific Mastercard. Have a gift certificate? There is an issue with your connection. Please try again OK Thank you OK OK Close Manage Cookies\", metadata={'source': 'https://www.priceless.com/m/filter/options/category/506'}))"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "urls = ['https://www.priceless.com/m/filter/options/category/506', \n",
                "        'https://www.priceless.com/m/filter/options/category/510',\n",
                "        'https://www.priceless.com/m/filter/options/location/9716/trk/20211/']\n",
                "documents = []\n",
                "\n",
                "for doc in tqdm(docs):\n",
                "    src = doc.metadata['source']\n",
                "    url = src.replace('rtdocs/', 'https://').replace('index.html', '').replace('.html', '')\n",
                "    if not url in urls:\n",
                "        continue\n",
                "\n",
                "    documents.append(doc)\n",
                "\n",
                "len(documents), documents[0]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d226d19c",
            "metadata": {},
            "source": [
                "## Model preparation"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dde35bcc",
            "metadata": {},
            "source": [
                "- download `gpt4all` model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d5237686",
            "metadata": {},
            "outputs": [],
            "source": [
                "#https://the-eye.eu/public/AI/models/nomic-ai/gpt4all/gpt4all-lora-quantized.bin"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "57520ec5",
            "metadata": {},
            "source": [
                "- download `llama.cpp` 7B model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2199b5a1",
            "metadata": {},
            "outputs": [],
            "source": [
                "!python3.10 -m llama.download --model_size 7B --folder ../../models/llama/"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0c21e391",
            "metadata": {},
            "source": [
                "- transform `gpt4all` model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4c11c606",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install pyllamacpp\n",
                "!pyllamacpp-convert-gpt4all ../../models/gpt4all-lora-quantized.bin ../../models/llama/tokenizer.model ../../models/gpt4all-lora-q-converted.bin"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "72d09e27",
            "metadata": {},
            "source": [
                "## `langchain` Demo\n",
                "\n",
                "Example of running a prompt using `langchain`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "65c9ca4d",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.llms import LlamaCpp\n",
                "from langchain import PromptTemplate, LLMChain"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "500eb501",
            "metadata": {},
            "source": [
                "- set up prompt template:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "60202ce2",
            "metadata": {},
            "outputs": [],
            "source": [
                "template = \"\"\"\n",
                "Question: {question}\n",
                "Answer: \n",
                "\"\"\"\n",
                "\n",
                "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ad12a227",
            "metadata": {},
            "source": [
                "- load model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "a858d90f",
            "metadata": {},
            "outputs": [],
            "source": [
                "GPT4ALL_MODEL_PATH = \"../../models/gpt4all-lora-q-converted.bin\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "5d83c596",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 12.5 ms, sys: 7.89 ms, total: 20.4 ms\n",
                        "Wall time: 60.8 ms\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "llama.cpp: loading model from ../../models/gpt4all-lora-q-converted.bin\n",
                        "llama_model_load_internal: format     = ggjt v1 (latest)\n",
                        "llama_model_load_internal: n_vocab    = 32001\n",
                        "llama_model_load_internal: n_ctx      = 512\n",
                        "llama_model_load_internal: n_embd     = 4096\n",
                        "llama_model_load_internal: n_mult     = 256\n",
                        "llama_model_load_internal: n_head     = 32\n",
                        "llama_model_load_internal: n_layer    = 32\n",
                        "llama_model_load_internal: n_rot      = 128\n",
                        "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
                        "llama_model_load_internal: n_ff       = 11008\n",
                        "llama_model_load_internal: n_parts    = 1\n",
                        "llama_model_load_internal: model size = 7B\n",
                        "llama_model_load_internal: ggml ctx size =  68.20 KB\n",
                        "llama_model_load_internal: mem required  = 5809.34 MB (+ 2052.00 MB per state)\n",
                        "llama_init_from_file: kv self size  =  512.00 MB\n",
                        "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "llm = LlamaCpp(model_path=GPT4ALL_MODEL_PATH)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a40b30f6",
            "metadata": {},
            "source": [
                "- create language chain using prompt template and loaded model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "112a5b4b",
            "metadata": {},
            "outputs": [],
            "source": [
                "llm_chain = LLMChain(prompt=prompt, llm=llm)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5351ee46",
            "metadata": {},
            "source": [
                "- run prompt:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "3d56cc93",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 1min 34s, sys: 54 s, total: 2min 28s\n",
                        "Wall time: 2min 53s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "llama_print_timings:        load time =  7761.79 ms\n",
                        "llama_print_timings:      sample time =   187.98 ms /   247 runs   (    0.76 ms per run)\n",
                        "llama_print_timings: prompt eval time = 15628.07 ms /    14 tokens ( 1116.29 ms per token)\n",
                        "llama_print_timings:        eval time = 157936.61 ms /   246 runs   (  642.02 ms per run)\n",
                        "llama_print_timings:       total time = 173805.38 ms\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "\" There are many ways to enjoy entertainment in New York. Here are some suggestions for things to do:\\n1. Visit a Broadway show: With over 40 venues to choose from, there is always a great performance happening on Broadway.\\n2. Attend a concert or festival: New York has a huge music scene with many concerts and festivals throughout the year.\\n3. Explore museums and galleries: From world-class art museums like The Met, MoMA and Guggenheim to historical institutions like the National September 11 Memorial & Museum, there are endless opportunities to learn and be inspired in New York City.\\n4. Experience live sports: If you are a sports fanatic, New York is home to many professional teams such as the Knicks, Rangers, Mets, Yankees, and Jets who offer tickets for public sale. \\n5. Have dinner at one of NYC's best restaurants: Whether you're in the mood for Italian, Japanese, or Korean cuisine, New York is home to some of the world’s most iconic and acclaimed restaurants.\""
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "question = \"Entertainment in New York\"\n",
                "\n",
                "llm_chain.run(question)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "id": "a124516e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 5min 9s, sys: 9min 32s, total: 14min 42s\n",
                        "Wall time: 55min 18s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "llama_print_timings:        load time =  7867.97 ms\n",
                        "llama_print_timings:      sample time =   220.69 ms /   256 runs   (    0.86 ms per run)\n",
                        "llama_print_timings: prompt eval time = 23563.58 ms /    22 tokens ( 1071.07 ms per token)\n",
                        "llama_print_timings:        eval time = 3294263.72 ms /   255 runs   (12918.68 ms per run)\n",
                        "llama_print_timings:       total time = 3318321.43 ms\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "\"1. Broadway Shows and Theatre Districts: New York City is well-known for its theatres, especially on Broadway, which has been home to some of the most famous musicals in history such as The Phantom of the Opera, Les Misérables, Wicked, Hamilton, and The Lion King. Beyond Broadway, there are also other theatre districts that showcase various productions from all over the world.\\n2. Live Music Scene: New York City is a hub for live music in the United States. From legendary jazz clubs like The Village Vanguard to iconic rock venues such as Madison Square Garden and Webster Hall, there are endless opportunities to experience great live music all over NYC.\\n3. Festivals and Events: There are tons of festivals and events happening in New York City throughout the year, ranging from the world-famous Macy's Thanksgiving Day Parade to NYC Pride, The Tribeca Film Festival, and The New York Comic Con.\\n4. Sports Teams: New York is home to some of the most famous sports teams in the United States, such as the Knicks (NBA), Rangers (NHL\""
                        ]
                    },
                    "execution_count": 45,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "question = \"纽约的娱乐\"\n",
                "\n",
                "llm_chain.run(question)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "99219ee6",
            "metadata": {},
            "source": [
                "## Generating Embeddings\n",
                "\n",
                "We can also use the model to generate embddings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "110cace5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 9.98 ms, sys: 6.52 ms, total: 16.5 ms\n",
                        "Wall time: 49.3 ms\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "llama.cpp: loading model from ../../models/gpt4all-lora-q-converted.bin\n",
                        "llama_model_load_internal: format     = ggjt v1 (latest)\n",
                        "llama_model_load_internal: n_vocab    = 32001\n",
                        "llama_model_load_internal: n_ctx      = 512\n",
                        "llama_model_load_internal: n_embd     = 4096\n",
                        "llama_model_load_internal: n_mult     = 256\n",
                        "llama_model_load_internal: n_head     = 32\n",
                        "llama_model_load_internal: n_layer    = 32\n",
                        "llama_model_load_internal: n_rot      = 128\n",
                        "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
                        "llama_model_load_internal: n_ff       = 11008\n",
                        "llama_model_load_internal: n_parts    = 1\n",
                        "llama_model_load_internal: model size = 7B\n",
                        "llama_model_load_internal: ggml ctx size =  68.20 KB\n",
                        "llama_model_load_internal: mem required  = 5809.34 MB (+ 2052.00 MB per state)\n",
                        "llama_init_from_file: kv self size  =  512.00 MB\n",
                        "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "from langchain.embeddings import LlamaCppEmbeddings\n",
                "llama_embeddings = LlamaCppEmbeddings(model_path=GPT4ALL_MODEL_PATH)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "c90c768e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 2.53 s, sys: 2.35 s, total: 4.88 s\n",
                        "Wall time: 6.59 s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  6586.00 ms /     7 tokens (  940.86 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  6587.02 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "text = \"This is a test document.\"\n",
                "\n",
                "query_result = llama_embeddings.embed_query(text)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "7e8efbf4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 2.54 s, sys: 2.36 s, total: 4.91 s\n",
                        "Wall time: 7.08 s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  7074.05 ms /     7 tokens ( 1010.58 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  7074.87 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "doc_result = llama_embeddings.embed_documents([text])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "20f62806",
            "metadata": {},
            "source": [
                "## Example Query Supported by a Document Based Knowledge Source\n",
                "\n",
                "Example document query using the example from the [`langchain` docs](https://python.langchain.com/en/latest/use_cases/question_answering.html).\n",
                "\n",
                "The idea is to run the query against a document source to retrieve some relevant context, and use that as part of the prompt context."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "2d8fe74f",
            "metadata": {},
            "source": [
                "Now let's try with some source documents."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "id": "61ba7abd",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 2.76 ms, sys: 2.19 ms, total: 4.95 ms\n",
                        "Wall time: 9.14 ms\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(60,\n",
                            " Document(page_content='### Add to wishlist Follow ADD TO CART Waitlist 0 Log in Sign up Language Currency Interests Locations * * * Mastercard.com About Priceless Contact us ADVANCED SEARCH All Experiences Interests Entertainment Arts and Culture Sports Culinary Travel More... Shopping Less... Locations Argentina Australia Austria Brazil Bulgaria More... Canada Chile China Colombia Croatia Czechia Fiji France Germany Greece Hong Kong India Indonesia Ireland Italy Japan Kenya Macau Malaysia Maldives Mexico Morocco', metadata={'source': 'https://www.priceless.com/m/filter/options/category/506'}))"
                        ]
                    },
                    "execution_count": 68,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                "\n",
                "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
                "texts = text_splitter.split_documents(documents)\n",
                "len(texts), texts[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "id": "a425cf67",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:chromadb.telemetry.posthog:Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n",
                        "INFO:chromadb:Running Chroma using direct local API.\n",
                        "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: rtdocs/gpt4all\n",
                        "INFO:chromadb.db.duckdb:No existing DB found in rtdocs/gpt4all, skipping load\n",
                        "INFO:chromadb.db.duckdb:No existing DB found in rtdocs/gpt4all, skipping load\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 130048.66 ms /   114 tokens ( 1140.78 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 130062.01 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 110476.68 ms /   103 tokens ( 1072.59 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 110483.38 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 141010.33 ms /   133 tokens ( 1060.23 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 141018.08 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 182576.43 ms /   171 tokens ( 1067.70 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 182597.22 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 185490.62 ms /   178 tokens ( 1042.08 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 185500.39 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 156976.09 ms /   144 tokens ( 1090.11 ms per token)\n",
                        "llama_print_timings:        eval time =  7716.38 ms /     1 runs   ( 7716.38 ms per run)\n",
                        "llama_print_timings:       total time = 164705.31 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 130558.53 ms /   120 tokens ( 1087.99 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 130569.20 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 153118.73 ms /   138 tokens ( 1109.56 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 153130.43 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 182918.94 ms /   176 tokens ( 1039.31 ms per token)\n",
                        "llama_print_timings:        eval time =  7649.79 ms /     1 runs   ( 7649.79 ms per run)\n",
                        "llama_print_timings:       total time = 190578.69 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 189761.81 ms /   178 tokens ( 1066.08 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 189771.97 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 156987.93 ms /   148 tokens ( 1060.73 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 157000.28 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 140253.82 ms /   132 tokens ( 1062.53 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 140263.36 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 152814.71 ms /   139 tokens ( 1099.39 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 152823.46 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 186364.55 ms /   170 tokens ( 1096.26 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 186374.85 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 153659.88 ms /   140 tokens ( 1097.57 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 153667.40 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 126573.71 ms /   120 tokens ( 1054.78 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 126583.89 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 207752.34 ms /   196 tokens ( 1059.96 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 207762.42 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 140234.26 ms /   134 tokens ( 1046.52 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 140245.85 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 136634.68 ms /   128 tokens ( 1067.46 ms per token)\n",
                        "llama_print_timings:        eval time =  7946.85 ms /     1 runs   ( 7946.85 ms per run)\n",
                        "llama_print_timings:       total time = 144588.96 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 102660.48 ms /    95 tokens ( 1080.64 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 102668.54 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 127990.46 ms /   114 tokens ( 1122.72 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 127997.33 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 115591.60 ms /   103 tokens ( 1122.25 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 115603.79 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 153412.43 ms /   133 tokens ( 1153.48 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 153424.69 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 185371.12 ms /   171 tokens ( 1084.04 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 185385.54 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 200148.70 ms /   178 tokens ( 1124.43 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 200159.31 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 151574.30 ms /   144 tokens ( 1052.60 ms per token)\n",
                        "llama_print_timings:        eval time =  7925.18 ms /     1 runs   ( 7925.18 ms per run)\n",
                        "llama_print_timings:       total time = 159510.36 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 127901.04 ms /   120 tokens ( 1065.84 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 127912.50 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 145995.23 ms /   138 tokens ( 1057.94 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 146004.96 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 188287.61 ms /   176 tokens ( 1069.82 ms per token)\n",
                        "llama_print_timings:        eval time =  7910.74 ms /     1 runs   ( 7910.74 ms per run)\n",
                        "llama_print_timings:       total time = 196208.61 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 191390.42 ms /   178 tokens ( 1075.23 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 191401.18 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 156699.89 ms /   148 tokens ( 1058.78 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 156711.29 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 143058.98 ms /   132 tokens ( 1083.78 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 143066.77 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 146754.13 ms /   139 tokens ( 1055.79 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 146763.51 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 177998.79 ms /   168 tokens ( 1059.52 ms per token)\n",
                        "llama_print_timings:        eval time =  8059.73 ms /     1 runs   ( 8059.73 ms per run)\n",
                        "llama_print_timings:       total time = 186069.62 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 137173.48 ms /   140 tokens (  979.81 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 137183.06 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  9781.42 ms /   120 tokens (   81.51 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  9788.16 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 27499.22 ms /   196 tokens (  140.30 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 27505.78 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  8887.90 ms /   134 tokens (   66.33 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  8893.01 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  8492.00 ms /   128 tokens (   66.34 ms per token)\n",
                        "llama_print_timings:        eval time =    74.64 ms /     1 runs   (   74.64 ms per run)\n",
                        "llama_print_timings:       total time =  8571.51 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  5898.68 ms /    95 tokens (   62.09 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  5902.40 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  6958.04 ms /   114 tokens (   61.04 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  6960.57 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  6632.04 ms /   103 tokens (   64.39 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  6633.55 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  8280.87 ms /   133 tokens (   62.26 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  8284.41 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 10568.81 ms /   171 tokens (   61.81 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 10571.28 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 12170.40 ms /   178 tokens (   68.37 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 12175.53 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  8837.34 ms /   144 tokens (   61.37 ms per token)\n",
                        "llama_print_timings:        eval time =    71.34 ms /     1 runs   (   71.34 ms per run)\n",
                        "llama_print_timings:       total time =  8913.20 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  7338.73 ms /   120 tokens (   61.16 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  7340.73 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  8465.77 ms /   138 tokens (   61.35 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  8468.41 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 10968.66 ms /   176 tokens (   62.32 ms per token)\n",
                        "llama_print_timings:        eval time =    71.36 ms /     1 runs   (   71.36 ms per run)\n",
                        "llama_print_timings:       total time = 11042.47 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 11345.22 ms /   178 tokens (   63.74 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 11347.77 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 10025.65 ms /   148 tokens (   67.74 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 10029.30 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  8188.25 ms /   132 tokens (   62.03 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  8192.59 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  8476.08 ms /   139 tokens (   60.98 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  8478.73 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 10665.65 ms /   171 tokens (   62.37 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 10668.37 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  9973.47 ms /   140 tokens (   71.24 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  9976.52 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  7337.97 ms /   120 tokens (   61.15 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  7341.62 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 13888.90 ms /   196 tokens (   70.86 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 13891.86 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  9006.63 ms /   134 tokens (   67.21 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  9010.77 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  7759.62 ms /   128 tokens (   60.62 ms per token)\n",
                        "llama_print_timings:        eval time =    67.27 ms /     1 runs   (   67.27 ms per run)\n",
                        "llama_print_timings:       total time =  7830.68 ms\n",
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  5786.07 ms /    95 tokens (   60.91 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  5789.86 ms\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 47min 24s, sys: 29min 12s, total: 1h 16min 36s\n",
                        "Wall time: 1h 35min 6s\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(60, <langchain.vectorstores.chroma.Chroma at 0x12f8befb0>)"
                        ]
                    },
                    "execution_count": 69,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "from langchain.vectorstores import Chroma\n",
                "\n",
                "docsearch = Chroma.from_documents(texts, llama_embeddings, persist_directory='../data/docs/gpt4all')\n",
                "len(texts), docsearch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "id": "b6c9d033",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 251 µs, sys: 1.79 ms, total: 2.04 ms\n",
                        "Wall time: 7.79 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "from langchain.chains import RetrievalQA\n",
                "\n",
                "MIN_DOCS = 1\n",
                "\n",
                "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\",\n",
                "                                 retriever=docsearch.as_retriever(search_kwargs={\"k\": MIN_DOCS}))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2bb80c55",
            "metadata": {},
            "source": [
                "What do we get in response to our original query now?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "id": "05dcdc74",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Entertainment in New York\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "llama_print_timings:        load time =  6586.26 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time =  6873.69 ms /     7 tokens (  981.96 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time =  6874.77 ms\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 2min 45s, sys: 3min 39s, total: 6min 25s\n",
                        "Wall time: 10min 59s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "llama_print_timings:        load time =  7911.82 ms\n",
                        "llama_print_timings:      sample time =    44.57 ms /    51 runs   (    0.87 ms per run)\n",
                        "llama_print_timings: prompt eval time = 251544.37 ms /   228 tokens ( 1103.26 ms per token)\n",
                        "llama_print_timings:        eval time = 400569.15 ms /    50 runs   ( 8011.38 ms per run)\n",
                        "llama_print_timings:       total time = 652214.27 ms\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "' You may enjoy a variety of entertainment options such as Broadway shows, concerts and performances at Lincoln Center, theaters across town, or comedy clubs throughout the city. Additionally, there are many museums and galleries to visit for cultural experiences.'"
                        ]
                    },
                    "execution_count": 71,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(question)\n",
                "qa.run(question)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "ab369bed",
            "metadata": {},
            "source": [
                "## Comparison with OpenAI Embeddings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "id": "49a9c609",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from dotenv import load_dotenv\n",
                "from langchain.embeddings import OpenAIEmbeddings\n",
                "\n",
                "load_dotenv('../.env', override=True)\n",
                "openai_embeddings = OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 73,
            "id": "c6ffa19a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:chromadb.telemetry.posthog:Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n",
                        "INFO:chromadb:Running Chroma using direct local API.\n",
                        "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: rtdocs/openai\n",
                        "INFO:chromadb.db.duckdb:No existing DB found in rtdocs/openai, skipping load\n",
                        "INFO:chromadb.db.duckdb:No existing DB found in rtdocs/openai, skipping load\n",
                        "INFO:chromadb.db.duckdb:PersistentDuckDB del, about to run persist\n",
                        "INFO:chromadb.db.duckdb:Persisting DB to disk, putting it in the save folder: db\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 325 ms, sys: 124 ms, total: 448 ms\n",
                        "Wall time: 6.13 s\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(60, <langchain.vectorstores.chroma.Chroma at 0x12f8bf340>)"
                        ]
                    },
                    "execution_count": 73,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "from langchain.vectorstores import Chroma\n",
                "\n",
                "docsearch2 = Chroma.from_documents(texts, openai_embeddings, persist_directory='rtdocs/openai')\n",
                "len(texts), docsearch2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "id": "a47c3e54",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.llms import OpenAI\n",
                "\n",
                "qa2 = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0), chain_type=\"stuff\",\n",
                "                                 retriever=docsearch2.as_retriever(search_kwargs={\"k\": MIN_DOCS}))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "id": "6e1f3453",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Entertainment in New York\n",
                        "CPU times: user 5.38 ms, sys: 7.78 ms, total: 13.2 ms\n",
                        "Wall time: 1.32 s\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "' Entertainment in New York includes Broadway shows, comedy clubs, music venues, museums, and more.'"
                        ]
                    },
                    "execution_count": 92,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(question)\n",
                "qa2.run(question)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "id": "7efeb11a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'dimension': 1536,\n",
                        " 'index_fullness': 0.1,\n",
                        " 'namespaces': {'priceless-docs': {'vector_count': 201558},\n",
                        "                'priceless-docs-v2': {'vector_count': 174012},\n",
                        "                'priceless-docs-v3': {'vector_count': 148815}},\n",
                        " 'total_vector_count': 524385}\n"
                    ]
                }
            ],
            "source": [
                "from langchain.llms import OpenAI\n",
                "from langchain.vectorstores import Pinecone\n",
                "import pinecone\n",
                "\n",
                "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
                "PINECONE_ENVIRONMENT = os.environ.get(\"PINECONE_ENVIRONMENT\")\n",
                "PINECONE_INDEX = os.environ.get(\"PINECONE_INDEX\")\n",
                "PINECONE_NAME_SPACE = os.environ.get(\"PINECONE_NAME_SPACE\")\n",
                "\n",
                "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
                "index = pinecone.Index(PINECONE_INDEX)\n",
                "print(index.describe_index_stats())\n",
                "\n",
                "test_cone = Pinecone.from_documents(documents=[],\n",
                "                                    embedding=openai_embeddings,\n",
                "                                    index_name=PINECONE_INDEX)\n",
                "\n",
                "qa3 = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0), chain_type=\"stuff\",\n",
                "                                 retriever=test_cone.as_retriever(search_kwargs={\"k\": 3}))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "id": "a0c391b2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Entertainment in New York\n",
                        "CPU times: user 7.04 ms, sys: 1.97 ms, total: 9.02 ms\n",
                        "Wall time: 3.09 s\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "'\\n\\nNew York City is known for its vibrant entertainment scene. There are countless theaters, music venues, comedy clubs, and other entertainment options to choose from. From Broadway shows to stand-up comedy to live music, there is something for everyone in New York.'"
                        ]
                    },
                    "execution_count": 91,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(question)\n",
                "qa3.run(question)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "2e1ec5f0",
            "metadata": {},
            "source": [
                "We've tried to use GPT4ALL and OpenAI to generate embeddings for 3 HTML files which are returned by Priceless Chatbot when someone asks \"Entertainment in New York\". These files are split into 60 chunks with a chunk size of 500 tokens. Then we ask both models to use the generated embeddings vectors to run RetrievalQA on the same question. For comparison, we also tried to use OpenAI + priceless-docs-v3 pre-generated embeddings vectors which are stored at Pinecone to run the same query. At last, we append the answer from Priceless Chatbot.\n",
                "\n",
                "| Approach | Time to generate embeddings | Time to run query | Query result |\n",
                "| --- | --- | --- | --- |\n",
                "| GPT4ALL + Chroma (local) | 95m 6.4s | 10m 59.2s | ' You may enjoy a variety of entertainment options such as Broadway shows, concerts and performances at Lincoln Center, theaters across town, or comedy clubs throughout the city. Additionally, there are many museums and galleries to visit for cultural experiences.' |\n",
                "| OpenAI + Chroma (local) | 6.1s | 1.3s | ' Entertainment in New York includes Broadway shows, comedy clubs, music venues, museums, and more.' |\n",
                "| OpenAI + Pinecone (remote) | N/A | 3.1s | '\\n\\nNew York City is known for its vibrant entertainment scene. There are countless theaters, music venues, comedy clubs, and other entertainment options to choose from. From Broadway shows to stand-up comedy to live music, there is something for everyone in New York.' |\n",
                "| OpenAI/GPT-4 + Pinecone (remote) | N/A | N/A | 'Entertainment in New York includes an ultra-glamorous, intimate 150-seat theater that showcases talent across various forms of entertainment such as magic, music, comedy, and Broadway cabarets. Additionally, there is an elegant and lively restaurant and bar called Hidden Leaf, as well as the Midnight Cafe, a cocktail bar with a beverage program directed by Giuseppe Santochirico.' |"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
