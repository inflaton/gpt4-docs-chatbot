{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "5a005358",
            "metadata": {},
            "source": [
                "# Vicuna Langchain Demo\n",
                "\n",
                "Example of locally running [`Vicuna`](https://github.com/lm-sys/FastChat), a *llama.cpp* based large language model (LLM) under [`langchain`](https://github.com/hwchase17/langchain), in a Jupyter notebook running a Python 3.10 kernel."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "871e5f12",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "langchain                     0.0.142\n",
                        "torch                         2.0.0\n",
                        "torchvision                   0.15.1\n",
                        "llama-cpp-python              0.1.43\n",
                        "llama-index                   0.5.27\n",
                        "pyllama                       0.0.9\n",
                        "pyllamacpp                    2.1.2\n"
                    ]
                }
            ],
            "source": [
                "!pip install -qU chromadb langchain==0.0.142 tiktoken tqdm load_dotenv ipywidgets pinecone-client pyllama llama-index llama-cpp-python html2text pyllamacpp\n",
                "!pip list | grep langchain\n",
                "!pip list | grep torch\n",
                "!pip list | grep llama"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "bf25336f",
            "metadata": {},
            "source": [
                "## Data preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "633bef28",
            "metadata": {},
            "outputs": [],
            "source": [
                "def file_metadata(filename):\n",
                "    d = dict()\n",
                "    d[\"source\"] = filename.replace('../data/docs/', 'https://').replace('index.html', '').replace('.html', '')\n",
                "    return d"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "157af9ba",
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "from typing import Dict\n",
                "\n",
                "from llama_index.readers.file.base_parser import BaseParser\n",
                "\n",
                "class HtmlParser(BaseParser):\n",
                "    \"\"\"Html parser.\"\"\"\n",
                "\n",
                "    def _init_parser(self) -> Dict:\n",
                "        \"\"\"Init parser.\"\"\"\n",
                "        return {}\n",
                "\n",
                "    def parse_file(self, file: Path, errors: str = \"ignore\") -> str:\n",
                "        \"\"\"Parse file.\"\"\"\n",
                "        try:\n",
                "            import html2text\n",
                "        except ImportError:\n",
                "            raise ImportError(\n",
                "                \"html2text is required to read html files: `pip install html2text`\"\n",
                "            )\n",
                "        with open(file, \"r\") as fp:\n",
                "            text = fp.read()\n",
                "            text_maker = html2text.HTML2Text()\n",
                "            text_maker.ignore_links = True\n",
                "            text_maker.ignore_images = True\n",
                "            text_maker.bypass_tables = False\n",
                "            text = text_maker.handle(text)\n",
                "            # Remove extra white space\n",
                "            text = ' '.join(text.split())\n",
                "\n",
                "        return text"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "acfaa49e",
            "metadata": {},
            "outputs": [],
            "source": [
                "file_extractor: Dict[str, BaseParser] = {\n",
                "    \".htm\": HtmlParser(),\n",
                "    \".html\": HtmlParser(),\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "b8128240",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 10.4 s, sys: 275 ms, total: 10.7 s\n",
                        "Wall time: 11.5 s\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "171"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "from llama_index import SimpleDirectoryReader\n",
                "docs = SimpleDirectoryReader(input_dir='../data/docs/', recursive=True, file_extractor=file_extractor, file_metadata=file_metadata).load_langchain_documents()\n",
                "len(docs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "a23d691b",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "911b21b513e2425e905b6266778a06ab",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/171 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 6.7 ms, sys: 3.82 ms, total: 10.5 ms\n",
                        "Wall time: 9.84 ms\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(3,\n",
                            " Document(page_content=\"### Add to wishlist Follow ADD TO CART Waitlist 0 Log in Sign up Language Currency Interests Locations * * * Mastercard.com About Priceless Contact us ADVANCED SEARCH All Experiences Interests Entertainment Arts and Culture Sports Culinary Travel More... Shopping Less... Locations Argentina Australia Austria Brazil Bulgaria More... Canada Chile China Colombia Croatia Czechia Fiji France Germany Greece Hong Kong India Indonesia Ireland Italy Japan Kenya Macau Malaysia Maldives Mexico Morocco Netherlands New Zealand Nigeria Puerto Rico Romania Serbia Singapore South Africa Spain Sweden Thailand Turkey United Arab Emirates United Kingdom United States Uruguay Clear Selection ADVANCED SEARCH ADVANCED SEARCH All Experiences Interests Entertainment Arts and Culture Sports Culinary Travel More... Shopping Less... Locations Argentina Australia Austria Brazil Bulgaria More... Canada Chile China Colombia Croatia Czechia Fiji France Germany Greece Hong Kong India Indonesia Ireland Italy Japan Kenya Macau Malaysia Maldives Mexico Morocco Netherlands New Zealand Nigeria Puerto Rico Romania Serbia Singapore South Africa Spain Sweden Thailand Turkey United Arab Emirates United Kingdom United States Uruguay Clear Selection ADVANCED SEARCH Filter Location * All locations * Argentina (0) * All locations * Buenos Aires (0) * Australia (0) * All locations * Brisbane (0) * Melbourne (0) * Sydney (0) * Austria (0) * Brazil (0) * All locations * Rio de Janeiro (0) * São Paulo (0) * Trancoso (0) * Bulgaria (0) * Canada (0) * All locations * Montreal (0) * Toronto (0) * Chile (0) * All locations * Santiago (0) * China (0) * All locations * Beijing (0) * Colombia (0) * All locations * Bogotá (0) * Croatia (0) * Czech Republic (0) * All locations * Prague (0) * Fiji (0) * France (0) * All locations * Paris (0) * Germany (0) * All locations * Berlin (0) * Munich (0) * Greece (0) * Hong Kong (0) * India (0) * Indonesia (0) * All locations * Bali (0) * Ireland (0) * Italy (0) * All locations * Milan (0) * Rome (0) * Sicily (0) * Japan (0) * Kenya (0) * Macau (0) * Malaysia (0) * Mexico (0) * All locations * Mexico City (0) * Morocco (0) * Netherlands (0) * New Zealand (0) * Nigeria (0) * Puerto Rico (0) * All locations * San Juan (0) * Romania (0) * Serbia (0) * Singapore (0) * South Africa (0) * Spain (0) * All locations * Barcelona (0) * Madrid (0) * Sweden (0) * All locations * Stockholm (0) * Thailand (0) * All locations * Bangkok (0) * Turkey (0) * All locations * Istanbul (0) * United Arab Emirates (0) * United Kingdom (0) * All locations * London (0) * St Andrews (0) * United States (0) * All locations * Boston (0) * Chicago (0) * Hawaii (0) * Las Vegas (0) * Los Angeles (0) * Miami (0) * New York (0) * Uruguay (0) Categories * All categories * Arts and Culture * Sports * Culinary * Travel * Shopping * Entertainment * Giving back Time range Select from preset options Weekdays Only Weekends Only Next 2 weeks Next Month Next 3 Months Next 6 Months Or Must choose a from date first. from April 2023 Select Time Select Time *Please select time *Please select a date/time that is greater than the current date/time. All experiences take place in the local timezone. Mastercard product * All Mastercard products * Mastercard Black™ * World Elite™ Mastercard® * World Mastercard® * Platinum Mastercard® * World Mastercard Black Edition® * Gold Mastercard® * Titanium Mastercard™ * World Mastercard™ (Europe) * Mastercard® Standard * World Mastercard® Rewards * Mastercard Rewards Only Content Type * All content types * Experiences * Digital experiences * Articles * Auctions * Sweepstakes * Offers * All offers * Mastercard Travel Rewards * Mastercard Travel and Lifestyle Services * Benefits Filter Results : 1772 Listings Find Cancel Location * All locations * Argentina (0) * All locations * Buenos Aires (0) * Australia (0) * All locations * Brisbane (0) * Melbourne (0) * Sydney (0) * Austria (0) * Brazil (0) * All locations * Rio de Janeiro (0) * São Paulo (0) * Trancoso (0) * Bulgaria (0) * Canada (0) * All locations * Montreal (0) * Toronto (0) * Chile (0) * All locations * Santiago (0) * China (0) * All locations * Beijing (0) * Colombia (0) * All locations * Bogotá (0) * Croatia (0) * Czech Republic (0) * All locations * Prague (0) * Fiji (0) * France (0) * All locations * Paris (0) * Germany (0) * All locations * Berlin (0) * Munich (0) * Greece (0) * Hong Kong (0) * India (0) * Indonesia (0) * All locations * Bali (0) * Ireland (0) * Italy (0) * All locations * Milan (0) * Rome (0) * Sicily (0) * Japan (0) * Kenya (0) * Macau (0) * Malaysia (0) * Mexico (0) * All locations * Mexico City (0) * Morocco (0) * Netherlands (0) * New Zealand (0) * Nigeria (0) * Puerto Rico (0) * All locations * San Juan (0) * Romania (0) * Serbia (0) * Singapore (0) * South Africa (0) * Spain (0) * All locations * Barcelona (0) * Madrid (0) * Sweden (0) * All locations * Stockholm (0) * Thailand (0) * All locations * Bangkok (0) * Turkey (0) * All locations * Istanbul (0) * United Arab Emirates (0) * United Kingdom (0) * All locations * London (0) * St Andrews (0) * United States (0) * All locations * Boston (0) * Chicago (0) * Hawaii (0) * Las Vegas (0) * Los Angeles (0) * Miami (0) * New York (0) * Uruguay (0) Categories * All categories * Arts and Culture * Sports * Culinary * Travel * Shopping * Entertainment * Giving back Mastercard product * All Mastercard products * Mastercard Black™ * World Elite™ Mastercard® * World Mastercard® * Platinum Mastercard® * World Mastercard Black Edition® * Gold Mastercard® * Titanium Mastercard™ * World Mastercard™ (Europe) * Mastercard® Standard * World Mastercard® Rewards * Mastercard Rewards Only Time range Weekdays Only Weekends Only Next 2 weeks Next Month Next 3 Months Next 6 Months Or Specify time range April 2023 April 2023 Clear Selection Content type * All content types * Experiences * Digital experiences * Articles * Auctions * Sweepstakes * Offers * All offers * Mastercard Travel Rewards * Mastercard Travel and Lifestyle Services * Benefits # 1772 Results '' Clear All All Experiences 1772 Results \\\\- FILTER , '' Clear All View more Sorry, there are no results to display. Please check back soon as we are continually adding new results. You may also enjoy these offers Follow us * (opens in new tab) * (opens in new tab) * Contact us (opens in new tab) * Terms of Use (opens in new tab) * About Priceless (opens in new tab) * Privacy Notice (opens in new tab) * Mastercard.com (opens in new tab) * Manage cookies * Sitemap (opens in new tab) Mastercard and Priceless are registered trademarks, and the circles design is a trademark of Mastercard International Incorporated. ©2023 Mastercard as01-SI5-SCOPx5Txqt7jJhvBCZPV6N-SO0-U0-V-L1-H7-mA0-uA1-auto0-exec:0.487-ajax:0-total:0.487 Verify card Login details Done Register to reveal content specific to your Mastercard, including: * Priority access to events * Complimentary digital experiences * Exclusive content * Shopping discounts, travel rewards, and more! Continue Already have an account? Log in Email Password Password must be at least 8 characters with three of: uppercase, lowercase, numbers or special characters. Space, dictionary words and repetitive or sequential characters are not allowed. Location / Region Location / Region AfghanistanAlgeriaAngolaArgentinaArubaAustraliaAustriaAzerbaijanBahamasBahrainBelgiumBeninBoliviaBosnia and HerzegovinaBotswanaBrazilBulgariaBurkina FasoBurundiCameroonCanadaCape VerdeCayman IslandsCentral African RepublicChadChileChinaColombiaComorosCongoCosta RicaCote D'Ivoire (Ivory Coast)CroatiaCyprusCzech RepublicDemocratic Republic of the CongoDenmarkDjiboutiDominican RepublicEcuadorEgyptEl SalvadorEquatorial GuineaEstoniaEthiopiaFijiFinlandFranceGabonGambiaGermanyGhanaGreeceGuatemalaGuineaGuinea- BissauHondurasHong KongHungaryIndiaIndonesiaIraqIrelandIsraelItalyJamaicaJapanJordanKenyaKuwaitLatviaLebanonLesothoLiberiaLibyaLithuaniaLuxembourgMacaoMadagascarMalawiMalaysiaMaldivesMaliMaltaMauritaniaMauritiusMexicoMoldovaMontenegroMoroccoMozambiqueNamibiaNetherlandsNew ZealandNicaraguaNigerNigeriaNorth MacedoniaNorwayOmanPakistanPalestinePanamaParaguayPeruPhilippinesPolandPortugalPuerto RicoQatarRomaniaRwandaSaudi ArabiaSenegalSerbiaSeychellesSierra LeoneSingaporeSlovakiaSloveniaSomaliaSouth AfricaSouth KoreaSpainSri LankaSwazilandSwedenSwitzerlandTaiwanTanzaniaThailandTogoTunisiaTurkeyTurks and Caicos IslandsUgandaUnited Arab EmiratesUnited KingdomUnited StatesUruguayVietnamYemenZambiaZimbabwe I agree that Mastercard International Inc. and its affiliates may use my contact details and interactions with priceless.com to send me personalized marketing communications about all Priceless programs. Information on Mastercard’s privacy practices is available in the priceless.com Privacy Notice. By clicking Sign Up, I confirm that I have read and agree to the Terms of Use for priceless.com. Submit Thank you! Please check your email to complete registration. You're all set! Start Something Priceless Explore priceless.com Already have an account? Log in here # Connect to Priceless * * Log In * Create Account Forgot Password? * * Sign up The Terms of Use and Privacy Notice for Priceless have been updated since you last logged in. * * *By clicking “Continue”, I acknowledge that I have read and understand the Terms of Use for Priceless. I also understand that my personal data will be processed by Mastercard International Inc. and its affiliates in the context of Priceless as described in the Privacy Notice. * * * Continue Complete your registration to unlock unique experiences tailored to your specific Mastercard. Have a gift certificate? There is an issue with your connection. Please try again OK Thank you OK OK Close Manage Cookies\", metadata={'source': 'https://www.priceless.com/m/filter/options/category/506'}))"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "urls = ['https://www.priceless.com/m/filter/options/category/506', \n",
                "        'https://www.priceless.com/m/filter/options/category/510',\n",
                "        'https://www.priceless.com/m/filter/options/location/9716/trk/20211/']\n",
                "documents = []\n",
                "\n",
                "for doc in tqdm(docs):\n",
                "    src = doc.metadata['source']\n",
                "    url = src.replace('rtdocs/', 'https://').replace('index.html', '').replace('.html', '')\n",
                "    if not url in urls:\n",
                "        continue\n",
                "\n",
                "    documents.append(doc)\n",
                "\n",
                "len(documents), documents[0]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d226d19c",
            "metadata": {},
            "source": [
                "## Model preparation"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "dde35bcc",
            "metadata": {},
            "source": [
                "Download [`vicuna` model](https://huggingface.co/eachadea/ggml-vicuna-13b-1.1), choosing between q5_0 and q5_1:\n",
                "\n",
                "> q5_1 or 5_0 are the latest and most performant implementations. The former is slightly more accurate at the cost of a bit of performance. Most users should use one of the two. "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "72d09e27",
            "metadata": {},
            "source": [
                "- import libs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "65c9ca4d",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.llms import LlamaCpp\n",
                "from langchain import PromptTemplate, LLMChain"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "500eb501",
            "metadata": {},
            "source": [
                "- set up prompt template:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "60202ce2",
            "metadata": {},
            "outputs": [],
            "source": [
                "template = \"\"\"\n",
                "Question: {question}\n",
                "Answer: \n",
                "\"\"\"\n",
                "\n",
                "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "ad12a227",
            "metadata": {},
            "source": [
                "- create language chain using prompt template and q5_0 model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "a285c0b1",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 12.2 ms, sys: 34.9 ms, total: 47.1 ms\n",
                        "Wall time: 111 ms\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "llama.cpp: loading model from ../../models/ggml-vic13b-q5_0.bin\n",
                        "llama_model_load_internal: format     = ggjt v1 (latest)\n",
                        "llama_model_load_internal: n_vocab    = 32000\n",
                        "llama_model_load_internal: n_ctx      = 512\n",
                        "llama_model_load_internal: n_embd     = 5120\n",
                        "llama_model_load_internal: n_mult     = 256\n",
                        "llama_model_load_internal: n_head     = 40\n",
                        "llama_model_load_internal: n_layer    = 40\n",
                        "llama_model_load_internal: n_rot      = 128\n",
                        "llama_model_load_internal: ftype      = 8 (mostly Q5_0)\n",
                        "llama_model_load_internal: n_ff       = 13824\n",
                        "llama_model_load_internal: n_parts    = 1\n",
                        "llama_model_load_internal: model size = 13B\n",
                        "llama_model_load_internal: ggml ctx size =  85.08 KB\n",
                        "llama_model_load_internal: mem required  = 10583.26 MB (+ 3216.00 MB per state)\n",
                        "llama_init_from_file: kv self size  =  800.00 MB\n",
                        "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "MODEL_PATH = \"../../models/ggml-vic13b-q5_0.bin\"\n",
                "llm = LlamaCpp(model_path=MODEL_PATH)\n",
                "llm_chain = LLMChain(prompt=prompt, llm=llm)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "52b8fa63",
            "metadata": {},
            "source": [
                "- run prompt:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "8a230e8a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 4min 43s, sys: 10min 37s, total: 15min 20s\n",
                        "Wall time: 5h 2min 23s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "llama_print_timings:        load time = 17435.00 ms\n",
                        "llama_print_timings:      sample time =    83.14 ms /   104 runs   (    0.80 ms per run)\n",
                        "llama_print_timings: prompt eval time = 52439.86 ms /    20 tokens ( 2621.99 ms per token)\n",
                        "llama_print_timings:        eval time = 18083661.28 ms /   103 runs   (175569.53 ms per run)\n",
                        "llama_print_timings:       total time = 18143542.49 ms\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "'\\n| Main Course | Sub Categories |\\n| --- | --- |\\n| Museums | Art, History, Science & Technology, Natural History |\\n| Broadway Shows | Musicals, Plays, Off-Broadway |\\n| Sports | Baseball, Basketball, Football, Hockey, Soccer |\\n| Food | American, Italian, Chinese, Japanese, Mexican, French, Indian |\\n| Music | Jazz, Rock, Pop, Classical, Hip Hop, R&B |'"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "question = \"Can you recommend any entertainment in New York?\"\n",
                "\n",
                "llm_chain.run(question)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "dee804c1",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "| Main Course | Sub Categories |\n",
                        "| --- | --- |\n",
                        "| Museums | Art, History, Science & Technology, Natural History |\n",
                        "| Broadway Shows | Musicals, Plays, Off-Broadway |\n",
                        "| Sports | Baseball, Basketball, Football, Hockey, Soccer |\n",
                        "| Food | American, Italian, Chinese, Japanese, Mexican, French, Indian |\n",
                        "| Music | Jazz, Rock, Pop, Classical, Hip Hop, R&B |\n"
                    ]
                }
            ],
            "source": [
                "print('\\n| Main Course | Sub Categories |\\n| --- | --- |\\n| Museums | Art, History, Science & Technology, Natural History |\\n| Broadway Shows | Musicals, Plays, Off-Broadway |\\n| Sports | Baseball, Basketball, Football, Hockey, Soccer |\\n| Food | American, Italian, Chinese, Japanese, Mexican, French, Indian |\\n| Music | Jazz, Rock, Pop, Classical, Hip Hop, R&B |')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "d5122962",
            "metadata": {},
            "source": [
                "| Main Course | Sub Categories |\n",
                "| --- | --- |\n",
                "| Museums | Art, History, Science & Technology, Natural History |\n",
                "| Broadway Shows | Musicals, Plays, Off-Broadway |\n",
                "| Sports | Baseball, Basketball, Football, Hockey, Soccer |\n",
                "| Food | American, Italian, Chinese, Japanese, Mexican, French, Indian |\n",
                "| Music | Jazz, Rock, Pop, Classical, Hip Hop, R&B |"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "a40b30f6",
            "metadata": {},
            "source": [
                "- create language chain using prompt template and q5_1 model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "5d83c596",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 12 ms, sys: 31.7 ms, total: 43.7 ms\n",
                        "Wall time: 110 ms\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "llama.cpp: loading model from ../../models/ggml-vic13b-q5_1.bin\n",
                        "llama_model_load_internal: format     = ggjt v1 (latest)\n",
                        "llama_model_load_internal: n_vocab    = 32000\n",
                        "llama_model_load_internal: n_ctx      = 512\n",
                        "llama_model_load_internal: n_embd     = 5120\n",
                        "llama_model_load_internal: n_mult     = 256\n",
                        "llama_model_load_internal: n_head     = 40\n",
                        "llama_model_load_internal: n_layer    = 40\n",
                        "llama_model_load_internal: n_rot      = 128\n",
                        "llama_model_load_internal: ftype      = 9 (mostly Q5_1)\n",
                        "llama_model_load_internal: n_ff       = 13824\n",
                        "llama_model_load_internal: n_parts    = 1\n",
                        "llama_model_load_internal: model size = 13B\n",
                        "llama_model_load_internal: ggml ctx size =  85.08 KB\n",
                        "llama_model_load_internal: mem required  = 11359.04 MB (+ 3216.00 MB per state)\n",
                        "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n",
                        "llama_init_from_file: kv self size  =  800.00 MB\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "MODEL_PATH = \"../../models/ggml-vic13b-q5_1.bin\"\n",
                "llm = LlamaCpp(model_path=MODEL_PATH)\n",
                "llm_chain = LLMChain(prompt=prompt, llm=llm)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5351ee46",
            "metadata": {},
            "source": [
                "- run prompt:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "3d56cc93",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Llama.generate: prefix-match hit\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 2min 54s, sys: 6min 39s, total: 9min 33s\n",
                        "Wall time: 1h 16min 7s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "llama_print_timings:        load time = 19284.29 ms\n",
                        "llama_print_timings:      sample time =    45.58 ms /    61 runs   (    0.75 ms per run)\n",
                        "llama_print_timings: prompt eval time = 39975.31 ms /    15 tokens ( 2665.02 ms per token)\n",
                        "llama_print_timings:        eval time = 4523198.70 ms /    60 runs   (75386.65 ms per run)\n",
                        "llama_print_timings:       total time = 4567377.50 ms\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "'\\n| No. | Recommendation |\\n| --- | --- |\\n| 1 | Broadway shows, museums, Central Park, Times Square, Empire State Building, Statue of Liberty, shopping, restaurants, comedy clubs, bars and pubs, nightlife |'"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "question = \"Can you recommend any entertainment in New York?\"\n",
                "\n",
                "llm_chain.run(question)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "85bcaae0",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "| No. | Recommendation |\n",
                        "| --- | --- |\n",
                        "| 1 | Broadway shows, museums, Central Park, Times Square, Empire State Building, Statue of Liberty, shopping, restaurants, comedy clubs, bars and pubs, nightlife |\n"
                    ]
                }
            ],
            "source": [
                "print('\\n| No. | Recommendation |\\n| --- | --- |\\n| 1 | Broadway shows, museums, Central Park, Times Square, Empire State Building, Statue of Liberty, shopping, restaurants, comedy clubs, bars and pubs, nightlife |')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "54069a9f",
            "metadata": {},
            "source": [
                "| No. | Recommendation |\n",
                "| --- | --- |\n",
                "| 1 | Broadway shows, museums, Central Park, Times Square, Empire State Building, Statue of Liberty, shopping, restaurants, comedy clubs, bars and pubs, nightlife |"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "99219ee6",
            "metadata": {},
            "source": [
                "## Generating Embeddings\n",
                "\n",
                "As q5_1 model gives a better answer to question `Can you recommend any entertainment in New York?`, let us it to generate embeddings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "110cace5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 10.7 ms, sys: 10.8 ms, total: 21.5 ms\n",
                        "Wall time: 86.6 ms\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "llama.cpp: loading model from ../../models/ggml-vic13b-q5_1.bin\n",
                        "llama_model_load_internal: format     = ggjt v1 (latest)\n",
                        "llama_model_load_internal: n_vocab    = 32000\n",
                        "llama_model_load_internal: n_ctx      = 512\n",
                        "llama_model_load_internal: n_embd     = 5120\n",
                        "llama_model_load_internal: n_mult     = 256\n",
                        "llama_model_load_internal: n_head     = 40\n",
                        "llama_model_load_internal: n_layer    = 40\n",
                        "llama_model_load_internal: n_rot      = 128\n",
                        "llama_model_load_internal: ftype      = 9 (mostly Q5_1)\n",
                        "llama_model_load_internal: n_ff       = 13824\n",
                        "llama_model_load_internal: n_parts    = 1\n",
                        "llama_model_load_internal: model size = 13B\n",
                        "llama_model_load_internal: ggml ctx size =  85.08 KB\n",
                        "llama_model_load_internal: mem required  = 11359.04 MB (+ 3216.00 MB per state)\n",
                        "llama_init_from_file: kv self size  =  800.00 MB\n",
                        "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "from langchain.embeddings import LlamaCppEmbeddings\n",
                "MODEL_PATH = \"../../models/ggml-vic13b-q5_1.bin\"\n",
                "llama_embeddings = LlamaCppEmbeddings(model_path=MODEL_PATH)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "c90c768e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 6.83 s, sys: 7.05 s, total: 13.9 s\n",
                        "Wall time: 18.7 s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 18720.98 ms /     7 tokens ( 2674.43 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 18723.87 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "text = \"This is a test document.\"\n",
                "\n",
                "query_result = llama_embeddings.embed_query(text)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "7e8efbf4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 7.04 s, sys: 7.15 s, total: 14.2 s\n",
                        "Wall time: 19.9 s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 19905.06 ms /     7 tokens ( 2843.58 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 19908.13 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "doc_result = llama_embeddings.embed_documents([text])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "20f62806",
            "metadata": {},
            "source": [
                "## Example Query Supported by a Document Based Knowledge Source\n",
                "\n",
                "Example document query using the example from the [`langchain` docs](https://python.langchain.com/en/latest/use_cases/question_answering.html).\n",
                "\n",
                "The idea is to run the query against a document source to retrieve some relevant context, and use that as part of the prompt context."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "2d8fe74f",
            "metadata": {},
            "source": [
                "Now let's try with some source documents."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "61ba7abd",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 2.51 ms, sys: 568 µs, total: 3.08 ms\n",
                        "Wall time: 3.88 ms\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(60,\n",
                            " Document(page_content='### Add to wishlist Follow ADD TO CART Waitlist 0 Log in Sign up Language Currency Interests Locations * * * Mastercard.com About Priceless Contact us ADVANCED SEARCH All Experiences Interests Entertainment Arts and Culture Sports Culinary Travel More... Shopping Less... Locations Argentina Australia Austria Brazil Bulgaria More... Canada Chile China Colombia Croatia Czechia Fiji France Germany Greece Hong Kong India Indonesia Ireland Italy Japan Kenya Macau Malaysia Maldives Mexico Morocco', metadata={'source': 'https://www.priceless.com/m/filter/options/category/506'}))"
                        ]
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                "\n",
                "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
                "texts = text_splitter.split_documents(documents)\n",
                "len(texts), texts[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "a425cf67",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:chromadb.telemetry.posthog:Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n",
                        "INFO:chromadb:Running Chroma using direct local API.\n",
                        "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: ../data/vicuna\n",
                        "INFO:clickhouse_connect.driver.ctypes:Successfully imported ClickHouse Connect C data optimizations\n",
                        "INFO:clickhouse_connect.driver.ctypes:Successfully import ClickHouse Connect C/Numpy optimizations\n",
                        "INFO:clickhouse_connect.json_impl:Using orjson library for writing JSON byte strings\n",
                        "INFO:chromadb.db.duckdb:No existing DB found in ../data/vicuna, skipping load\n",
                        "INFO:chromadb.db.duckdb:No existing DB found in ../data/vicuna, skipping load\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 302484.61 ms /   114 tokens ( 2653.37 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 302547.35 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 261731.82 ms /   103 tokens ( 2541.09 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 261778.26 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 349355.08 ms /   133 tokens ( 2626.73 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 349413.55 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 465177.95 ms /   171 tokens ( 2720.34 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 465256.59 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 461351.20 ms /   178 tokens ( 2591.86 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 461425.00 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 361144.52 ms /   144 tokens ( 2507.95 ms per token)\n",
                        "llama_print_timings:        eval time = 19178.56 ms /     1 runs   (19178.56 ms per run)\n",
                        "llama_print_timings:       total time = 380383.82 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 598053.20 ms /   120 tokens ( 4983.78 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 598103.17 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1867022.31 ms /   138 tokens (13529.15 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 1867083.87 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1267870.98 ms /   176 tokens ( 7203.81 ms per token)\n",
                        "llama_print_timings:        eval time = 17870.09 ms /     1 runs   (17870.09 ms per run)\n",
                        "llama_print_timings:       total time = 1285822.28 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1223124.39 ms /   178 tokens ( 6871.49 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 1223211.42 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 386081.35 ms /   148 tokens ( 2608.66 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 386143.04 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 337395.15 ms /   132 tokens ( 2556.02 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 337452.72 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1266558.41 ms /   139 tokens ( 9111.93 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 1266622.71 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 2257769.53 ms /   170 tokens (13281.00 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 2257848.17 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 2468097.02 ms /   140 tokens (17629.26 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 2468153.20 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1218151.34 ms /   120 tokens (10151.26 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 1218214.29 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 2035972.20 ms /   196 tokens (10387.61 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 2036061.66 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1254169.64 ms /   134 tokens ( 9359.47 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 1254231.19 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 2808580.03 ms /   128 tokens (21942.03 ms per token)\n",
                        "llama_print_timings:        eval time = 17821.92 ms /     1 runs   (17821.92 ms per run)\n",
                        "llama_print_timings:       total time = 2826467.32 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1738433.82 ms /    95 tokens (18299.30 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 1738494.00 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1636096.83 ms /   114 tokens (14351.73 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 1636147.67 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 254099.88 ms /   103 tokens ( 2466.99 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 254144.27 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1558091.67 ms /   133 tokens (11714.97 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 1558151.34 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 2166128.48 ms /   171 tokens (12667.42 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 2166216.94 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 461058.86 ms /   178 tokens ( 2590.22 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 461138.54 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1861988.78 ms /   144 tokens (12930.48 ms per token)\n",
                        "llama_print_timings:        eval time = 17871.29 ms /     1 runs   (17871.29 ms per run)\n",
                        "llama_print_timings:       total time = 1879920.19 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1454458.12 ms /   120 tokens (12120.48 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 1454522.49 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 2156310.60 ms /   138 tokens (15625.44 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 2156372.94 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1990605.88 ms /   176 tokens (11310.26 ms per token)\n",
                        "llama_print_timings:        eval time = 23176.19 ms /     1 runs   (23176.19 ms per run)\n",
                        "llama_print_timings:       total time = 2013874.19 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 2003099.82 ms /   178 tokens (11253.37 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 2003194.07 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1601963.38 ms /   148 tokens (10824.08 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 1602041.95 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1537518.98 ms /   132 tokens (11647.87 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 1537590.54 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 2415240.10 ms /   139 tokens (17375.83 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 2415320.20 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 413421.40 ms /   168 tokens ( 2460.84 ms per token)\n",
                        "llama_print_timings:        eval time = 18243.76 ms /     1 runs   (18243.76 ms per run)\n",
                        "llama_print_timings:       total time = 431729.69 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 2187019.54 ms /   140 tokens (15621.57 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 2187071.44 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1309935.53 ms /   120 tokens (10916.13 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 1309997.06 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1042670.47 ms /   196 tokens ( 5319.75 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 1042759.69 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 349670.43 ms /   134 tokens ( 2609.48 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 349726.09 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 331159.39 ms /   128 tokens ( 2587.18 ms per token)\n",
                        "llama_print_timings:        eval time = 20009.73 ms /     1 runs   (20009.73 ms per run)\n",
                        "llama_print_timings:       total time = 351226.58 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 312877.46 ms /    95 tokens ( 3293.45 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 312918.55 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 313218.20 ms /   114 tokens ( 2747.53 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 313266.94 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 276203.97 ms /   103 tokens ( 2681.59 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 276248.47 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 357585.54 ms /   133 tokens ( 2688.61 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 357664.03 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 461371.70 ms /   171 tokens ( 2698.08 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 461443.30 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 475464.18 ms /   178 tokens ( 2671.15 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 475553.49 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 373071.04 ms /   144 tokens ( 2590.77 ms per token)\n",
                        "llama_print_timings:        eval time = 19258.23 ms /     1 runs   (19258.23 ms per run)\n",
                        "llama_print_timings:       total time = 392402.10 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 2169331.60 ms /   120 tokens (18077.76 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 2169398.09 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1574967.85 ms /   138 tokens (11412.81 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 1575037.82 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 794094.37 ms /   176 tokens ( 4511.90 ms per token)\n",
                        "llama_print_timings:        eval time = 18834.62 ms /     1 runs   (18834.62 ms per run)\n",
                        "llama_print_timings:       total time = 813009.22 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 487188.74 ms /   178 tokens ( 2737.02 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 487268.27 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 410473.39 ms /   148 tokens ( 2773.47 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 410547.72 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 361843.77 ms /   132 tokens ( 2741.24 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 361900.37 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1283984.54 ms /   139 tokens ( 9237.30 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 1284047.11 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 520049.36 ms /   171 tokens ( 3041.22 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 520137.52 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 381063.67 ms /   140 tokens ( 2721.88 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 381118.40 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 879872.37 ms /   120 tokens ( 7332.27 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 879930.91 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 1458219.79 ms /   196 tokens ( 7439.90 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 1458303.77 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 368637.05 ms /   134 tokens ( 2751.02 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 368711.55 ms\n",
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 802839.95 ms /   128 tokens ( 6272.19 ms per token)\n",
                        "llama_print_timings:        eval time = 1002413.09 ms /     1 runs   (1002413.09 ms per run)\n",
                        "llama_print_timings:       total time = 1805305.82 ms\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 2h 26min 12s, sys: 2h 15min 11s, total: 4h 41min 24s\n",
                        "Wall time: 18h 8min 21s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 400448.93 ms /    95 tokens ( 4215.25 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 400495.80 ms\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(60, <langchain.vectorstores.chroma.Chroma at 0x135d27b80>)"
                        ]
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "from langchain.vectorstores import Chroma\n",
                "\n",
                "docsearch = Chroma.from_documents(texts, llama_embeddings, persist_directory='../data/vicuna')\n",
                "len(texts), docsearch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "b6c9d033",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 531 µs, sys: 2.52 ms, total: 3.05 ms\n",
                        "Wall time: 6.85 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "from langchain.chains import RetrievalQA\n",
                "\n",
                "MIN_DOCS = 1\n",
                "\n",
                "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\",\n",
                "                                 retriever=docsearch.as_retriever(search_kwargs={\"k\": MIN_DOCS}))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2bb80c55",
            "metadata": {},
            "source": [
                "What do we get in response to our original query now?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "id": "05dcdc74",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Entertainment in New York\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "llama_print_timings:        load time = 18721.40 ms\n",
                        "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings: prompt eval time = 19865.81 ms /     7 tokens ( 2837.97 ms per token)\n",
                        "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
                        "llama_print_timings:       total time = 19870.24 ms\n",
                        "Llama.generate: prefix-match hit\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 8min 41s, sys: 16min 47s, total: 25min 29s\n",
                        "Wall time: 46min 41s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "llama_print_timings:        load time = 17435.00 ms\n",
                        "llama_print_timings:      sample time =   100.11 ms /   134 runs   (    0.75 ms per run)\n",
                        "llama_print_timings: prompt eval time = 484905.52 ms /   194 tokens ( 2499.51 ms per token)\n",
                        "llama_print_timings:        eval time = 2287258.68 ms /   133 runs   (17197.43 ms per run)\n",
                        "llama_print_timings:       total time = 2781126.80 ms\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "' Some of the popular entertainment options in New York City include Broadway shows, concerts at Madison Square Garden or the Barclays Center, comedy clubs like the Comedy Cellar, and sporting events at Yankee Stadium or Citi Field. Additionally, there are numerous museums and art galleries to explore throughout the city, such as the Metropolitan Museum of Art or the Museum of Modern Art. For those interested in outdoor activities, Central Park offers a variety of walking trails, gardens, and sports facilities, while the High Line is an elevated park built on an old railway line that provides stunning views of the city skyline.'"
                        ]
                    },
                    "execution_count": 28,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "question = \"Entertainment in New York\"\n",
                "\n",
                "print(question)\n",
                "qa.run(question)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "ab369bed",
            "metadata": {},
            "source": [
                "## Comparison with OpenAI Embeddings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "id": "49a9c609",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from dotenv import load_dotenv\n",
                "from langchain.embeddings import OpenAIEmbeddings\n",
                "\n",
                "load_dotenv('../.env', override=True)\n",
                "openai_embeddings = OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 73,
            "id": "c6ffa19a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:chromadb.telemetry.posthog:Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n",
                        "INFO:chromadb:Running Chroma using direct local API.\n",
                        "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: rtdocs/openai\n",
                        "INFO:chromadb.db.duckdb:No existing DB found in rtdocs/openai, skipping load\n",
                        "INFO:chromadb.db.duckdb:No existing DB found in rtdocs/openai, skipping load\n",
                        "INFO:chromadb.db.duckdb:PersistentDuckDB del, about to run persist\n",
                        "INFO:chromadb.db.duckdb:Persisting DB to disk, putting it in the save folder: db\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 325 ms, sys: 124 ms, total: 448 ms\n",
                        "Wall time: 6.13 s\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(60, <langchain.vectorstores.chroma.Chroma at 0x12f8bf340>)"
                        ]
                    },
                    "execution_count": 73,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "from langchain.vectorstores import Chroma\n",
                "\n",
                "docsearch2 = Chroma.from_documents(texts, openai_embeddings, persist_directory='../data/openai')\n",
                "len(texts), docsearch2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "id": "a47c3e54",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.llms import OpenAI\n",
                "\n",
                "qa2 = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0), chain_type=\"stuff\",\n",
                "                                 retriever=docsearch2.as_retriever(search_kwargs={\"k\": MIN_DOCS}))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "id": "6e1f3453",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Entertainment in New York\n",
                        "CPU times: user 5.38 ms, sys: 7.78 ms, total: 13.2 ms\n",
                        "Wall time: 1.32 s\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "' Entertainment in New York includes Broadway shows, comedy clubs, music venues, museums, and more.'"
                        ]
                    },
                    "execution_count": 92,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(question)\n",
                "qa2.run(question)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "id": "7efeb11a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'dimension': 1536,\n",
                        " 'index_fullness': 0.1,\n",
                        " 'namespaces': {'priceless-docs': {'vector_count': 201558},\n",
                        "                'priceless-docs-v2': {'vector_count': 174012},\n",
                        "                'priceless-docs-v3': {'vector_count': 148815}},\n",
                        " 'total_vector_count': 524385}\n"
                    ]
                }
            ],
            "source": [
                "from langchain.llms import OpenAI\n",
                "from langchain.vectorstores import Pinecone\n",
                "import pinecone\n",
                "\n",
                "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
                "PINECONE_ENVIRONMENT = os.environ.get(\"PINECONE_ENVIRONMENT\")\n",
                "PINECONE_INDEX = os.environ.get(\"PINECONE_INDEX\")\n",
                "PINECONE_NAME_SPACE = os.environ.get(\"PINECONE_NAME_SPACE\")\n",
                "\n",
                "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
                "index = pinecone.Index(PINECONE_INDEX)\n",
                "print(index.describe_index_stats())\n",
                "\n",
                "test_cone = Pinecone.from_documents(documents=[],\n",
                "                                    embedding=openai_embeddings,\n",
                "                                    index_name=PINECONE_INDEX)\n",
                "\n",
                "qa3 = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0), chain_type=\"stuff\",\n",
                "                                 retriever=test_cone.as_retriever(search_kwargs={\"k\": 3}))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "id": "a0c391b2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Entertainment in New York\n",
                        "CPU times: user 7.04 ms, sys: 1.97 ms, total: 9.02 ms\n",
                        "Wall time: 3.09 s\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "'\\n\\nNew York City is known for its vibrant entertainment scene. There are countless theaters, music venues, comedy clubs, and other entertainment options to choose from. From Broadway shows to stand-up comedy to live music, there is something for everyone in New York.'"
                        ]
                    },
                    "execution_count": 91,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(question)\n",
                "qa3.run(question)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "2e1ec5f0",
            "metadata": {},
            "source": [
                "We've tried to use Vicuna (q5_1), GPT4ALL and OpenAI to generate embeddings for 3 HTML files which are returned by Priceless Chatbot when someone asks \"Entertainment in New York\". These files are split into 60 chunks with a chunk size of 500 tokens. Then we ask all models to use the generated embeddings vectors to run RetrievalQA on the same question. For comparison, we also tried to use OpenAI + priceless-docs-v3 pre-generated embeddings vectors which are stored at Pinecone to run the same query. At last, we append the answer from Priceless Chatbot.\n",
                "\n",
                "| Approach | Time to generate embeddings | Time to run query | Query result |\n",
                "| --- | --- | --- | --- |\n",
                "| Vicuna + Chroma (local) | 1088m 21.3s | 46m 41s | ' Some of the popular entertainment options in New York City include Broadway shows, concerts at Madison Square Garden or the Barclays Center, comedy clubs like the Comedy Cellar, and sporting events at Yankee Stadium or Citi Field. Additionally, there are numerous museums and art galleries to explore throughout the city, such as the Metropolitan Museum of Art or the Museum of Modern Art. For those interested in outdoor activities, Central Park offers a variety of walking trails, gardens, and sports facilities, while the High Line is an elevated park built on an old railway line that provides stunning views of the city skyline.' |\n",
                "| GPT4ALL + Chroma (local) | 95m 6.4s | 10m 59.2s | ' You may enjoy a variety of entertainment options such as Broadway shows, concerts and performances at Lincoln Center, theaters across town, or comedy clubs throughout the city. Additionally, there are many museums and galleries to visit for cultural experiences.' |\n",
                "| OpenAI + Chroma (local) | 6.1s | 1.3s | ' Entertainment in New York includes Broadway shows, comedy clubs, music venues, museums, and more.' |\n",
                "| OpenAI + Pinecone (remote) | N/A | 3.1s | '\\n\\nNew York City is known for its vibrant entertainment scene. There are countless theaters, music venues, comedy clubs, and other entertainment options to choose from. From Broadway shows to stand-up comedy to live music, there is something for everyone in New York.' |\n",
                "| OpenAI/GPT-4 + Pinecone (remote) | N/A | N/A | 'Entertainment in New York includes an ultra-glamorous, intimate 150-seat theater that showcases talent across various forms of entertainment such as magic, music, comedy, and Broadway cabarets. Additionally, there is an elegant and lively restaurant and bar called Hidden Leaf, as well as the Midnight Cafe, a cocktail bar with a beverage program directed by Giuseppe Santochirico.' |"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
